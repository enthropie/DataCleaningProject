{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем данные\n",
    "\n",
    "df = pd.read_csv(\"sample-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Active classic boxers - There's a reason why o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Active sport boxer briefs - Skinning up Glory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Active sport briefs - These superbreathable no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alpine guide pants - Skin in, climb ice, switc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alpine wind jkt - On high ridges, steep ice an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>Cap 2 bottoms - Cut loose from the maddening c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>Cap 2 crew - This crew takes the edge off fick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>All-time shell - No need to use that morning T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>All-wear cargo shorts - All-Wear Cargo Shorts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>All-wear shorts - Time to simplify? Our All-We...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        description\n",
       "0      1  Active classic boxers - There's a reason why o...\n",
       "1      2  Active sport boxer briefs - Skinning up Glory ...\n",
       "2      3  Active sport briefs - These superbreathable no...\n",
       "3      4  Alpine guide pants - Skin in, climb ice, switc...\n",
       "4      5  Alpine wind jkt - On high ridges, steep ice an...\n",
       "..   ...                                                ...\n",
       "495  496  Cap 2 bottoms - Cut loose from the maddening c...\n",
       "496  497  Cap 2 crew - This crew takes the edge off fick...\n",
       "497  498  All-time shell - No need to use that morning T...\n",
       "498  499  All-wear cargo shorts - All-Wear Cargo Shorts ...\n",
       "499  500  All-wear shorts - Time to simplify? Our All-We...\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active classic boxers - There's a reason why o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Active sport boxer briefs - Skinning up Glory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Active sport briefs - These superbreathable no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpine guide pants - Skin in, climb ice, switc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alpine wind jkt - On high ridges, steep ice an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Active classic boxers - There's a reason why o...\n",
       "1  Active sport boxer briefs - Skinning up Glory ...\n",
       "2  Active sport briefs - These superbreathable no...\n",
       "3  Alpine guide pants - Skin in, climb ice, switc...\n",
       "4  Alpine wind jkt - On high ridges, steep ice an..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выделим текст из колонки 'description'\n",
    "train_text_df = pd.DataFrame({'text': df['description']})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# представим массив текстов в виде векторов с помощью TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\n",
    "text_embeddings = tfidf.fit_transform( train_text_df['text'] ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем косинусное расстояние между векторами\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarities = cosine_similarity(text_embeddings, text_embeddings)\n",
    "\n",
    "# Определим морог значимости\n",
    "threshold = 0.9\n",
    "\n",
    "# Найдем похожие тексты\n",
    "similar_texts_indices = np.where(cosine_similarities >= threshold)\n",
    "\n",
    "# Выводим результат\n",
    "for idx1, idx2 in zip(*similar_texts_indices):\n",
    "    if idx1 != idx2:\n",
    "        # with open(r'D:\\python\\collab\\skillfactory\\output.txt', 'a') as f:\n",
    "        #    f.write(f\"Text 1: {idx1} Text 2: {idx2} Cosine similarity: {cosine_similarities[idx1, idx2]}\\n\")\n",
    "        \n",
    "        if idx1 in result_dict:\n",
    "            result_dict[idx1].append(idx2)\n",
    "        else:\n",
    "            result_dict[idx1] = [idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: [158],\n",
       " 4: [307],\n",
       " 26: [27, 451],\n",
       " 27: [26, 451],\n",
       " 31: [461, 462],\n",
       " 34: [281],\n",
       " 36: [480, 481],\n",
       " 76: [360],\n",
       " 81: [379],\n",
       " 84: [196],\n",
       " 106: [350],\n",
       " 107: [108, 389],\n",
       " 108: [107, 389],\n",
       " 112: [113, 419],\n",
       " 113: [112],\n",
       " 117: [118, 349],\n",
       " 118: [117, 349],\n",
       " 140: [274],\n",
       " 152: [153, 354, 366],\n",
       " 153: [152, 354, 366],\n",
       " 158: [3],\n",
       " 178: [472],\n",
       " 183: [437],\n",
       " 187: [304],\n",
       " 196: [84],\n",
       " 199: [259, 264],\n",
       " 203: [415],\n",
       " 209: [363],\n",
       " 211: [381],\n",
       " 218: [290],\n",
       " 221: [241],\n",
       " 241: [221],\n",
       " 242: [251],\n",
       " 243: [252],\n",
       " 251: [242],\n",
       " 252: [243],\n",
       " 254: [261],\n",
       " 259: [199, 264],\n",
       " 261: [254],\n",
       " 262: [377],\n",
       " 264: [199, 259],\n",
       " 266: [385],\n",
       " 267: [386],\n",
       " 273: [326],\n",
       " 274: [140],\n",
       " 281: [34],\n",
       " 285: [491],\n",
       " 290: [218],\n",
       " 292: [404],\n",
       " 304: [187],\n",
       " 307: [4],\n",
       " 326: [273],\n",
       " 349: [117, 118],\n",
       " 350: [106],\n",
       " 354: [152, 153, 366],\n",
       " 360: [76],\n",
       " 363: [209],\n",
       " 366: [152, 153, 354],\n",
       " 368: [369],\n",
       " 369: [368],\n",
       " 377: [262],\n",
       " 378: [383],\n",
       " 379: [81],\n",
       " 381: [211],\n",
       " 383: [378],\n",
       " 385: [266],\n",
       " 386: [267],\n",
       " 389: [107, 108],\n",
       " 390: [391],\n",
       " 391: [390],\n",
       " 404: [292],\n",
       " 415: [203],\n",
       " 419: [112],\n",
       " 431: [432],\n",
       " 432: [431],\n",
       " 437: [183],\n",
       " 451: [26, 27],\n",
       " 454: [467],\n",
       " 461: [31, 462],\n",
       " 462: [31, 461],\n",
       " 467: [454],\n",
       " 472: [178],\n",
       " 480: [36, 481],\n",
       " 481: [36, 480],\n",
       " 491: [285]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Индексы товаров с похожими описаниями, для описаний, векторизированных с помощью TF-IDF\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Получим векторы embeddings с помощью word2vec\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "embeddings = gensim.downloader.load('word2vec-google-news-300')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "docs_vectors = pd.DataFrame()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors = pd.DataFrame()\n",
    "temp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22992\\2187133683.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  for doc in train_text_df['text'].str.lower().str.replace('[^a-z ]', ''):\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22992\\2187133683.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp = temp.append(pd.Series(word_vec), ignore_index = True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22992\\2187133683.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  docs_vectors = docs_vectors.append(doc_vector, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "# Исключим стоп слова, для каждого слова, для которого есть embedding - добавим вектор значений в коллекцию\n",
    "\n",
    "for doc in train_text_df['text'].str.lower().str.replace('[^a-z ]', ''):\n",
    "    temp = pd.DataFrame()\n",
    "    for word in doc.split(' '):\n",
    "        if word not in stopwords and word in embeddings:\n",
    "            try:\n",
    "                word_vec = embeddings[word]\n",
    "                temp = temp.append(pd.Series(word_vec), ignore_index = True)\n",
    "            except:\n",
    "                pass\n",
    "    # усредним значение векторов для одного документа\n",
    "    doc_vector = temp.mean()\n",
    "    if not doc_vector.isnull().values.any():\n",
    "        docs_vectors = docs_vectors.append(doc_vector, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings_w2v = docs_vectors.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_w2v = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем косинусное расстояние\n",
    "cosine_similarities = cosine_similarity(text_embeddings_w2v, text_embeddings_w2v)\n",
    "\n",
    "# Определим порог значимости\n",
    "threshold = 0.97\n",
    "\n",
    "# Найдем похожие тексты\n",
    "similar_texts_indices = np.where(cosine_similarities >= threshold)\n",
    "\n",
    "# Выводим результат\n",
    "for idx1, idx2 in zip(*similar_texts_indices):\n",
    "    if idx1 != idx2:\n",
    "       # with open(r'D:\\python\\collab\\skillfactory\\output_w2v.txt', 'a') as f:\n",
    "       #    f.write(f\"Text 1: {idx1} Text 2: {idx2} Cosine similarity: {cosine_similarities[idx1, idx2]}\\n\")\n",
    "       \n",
    "        if idx1 in result_dict_w2v:\n",
    "            result_dict_w2v[idx1].append(idx2)\n",
    "        else:\n",
    "            result_dict_w2v[idx1] = [idx2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: [158],\n",
       " 4: [307],\n",
       " 7: [219],\n",
       " 14: [15, 479, 483],\n",
       " 15: [14],\n",
       " 17: [170],\n",
       " 18: [493],\n",
       " 19: [339, 487],\n",
       " 20: [171],\n",
       " 21: [22, 173, 174, 358, 359, 496],\n",
       " 22: [21, 174, 358, 359],\n",
       " 23: [440, 442],\n",
       " 24: [175],\n",
       " 26: [27, 451],\n",
       " 27: [26, 451],\n",
       " 28: [453],\n",
       " 31: [461, 462],\n",
       " 34: [281],\n",
       " 36: [480, 481],\n",
       " 41: [420],\n",
       " 45: [408],\n",
       " 48: [133],\n",
       " 49: [438],\n",
       " 51: [443],\n",
       " 52: [341],\n",
       " 57: [62, 63, 64, 431, 432],\n",
       " 62: [57, 63, 64, 431, 432],\n",
       " 63: [57, 62, 64, 431, 432],\n",
       " 64: [57, 62, 63, 431, 432],\n",
       " 68: [237, 318],\n",
       " 71: [333],\n",
       " 72: [238, 334],\n",
       " 74: [76, 360],\n",
       " 75: [124],\n",
       " 76: [74, 360],\n",
       " 81: [379],\n",
       " 83: [393],\n",
       " 84: [196],\n",
       " 86: [87, 88, 89, 199, 200, 201, 259, 264, 265, 268, 406],\n",
       " 87: [86, 88, 89, 199, 200, 259, 264, 265, 268, 405, 406],\n",
       " 88: [86, 87, 89, 201, 265, 268, 405, 406],\n",
       " 89: [86, 87, 88, 201, 265, 268, 405, 406],\n",
       " 95: [209, 280],\n",
       " 96: [208],\n",
       " 105: [263],\n",
       " 106: [350],\n",
       " 107: [108, 389],\n",
       " 108: [107, 389],\n",
       " 109: [390, 391],\n",
       " 112: [113, 397, 419],\n",
       " 113: [112, 397, 419],\n",
       " 116: [244, 476],\n",
       " 117: [118, 349],\n",
       " 118: [117, 349],\n",
       " 119: [215],\n",
       " 124: [75],\n",
       " 133: [48],\n",
       " 140: [274],\n",
       " 142: [231],\n",
       " 143: [238],\n",
       " 152: [153, 354, 366, 454, 467],\n",
       " 153: [152, 354, 366, 454, 467],\n",
       " 158: [3],\n",
       " 167: [327, 329],\n",
       " 170: [17],\n",
       " 171: [20, 339, 340],\n",
       " 172: [495],\n",
       " 173: [21, 174, 358, 359, 496],\n",
       " 174: [21, 22, 173, 358, 359, 496],\n",
       " 175: [24],\n",
       " 178: [472],\n",
       " 183: [437],\n",
       " 184: [314],\n",
       " 187: [304],\n",
       " 193: [313],\n",
       " 196: [84],\n",
       " 199: [86, 87, 200, 259, 264, 265, 405],\n",
       " 200: [86, 87, 199, 259, 264, 265],\n",
       " 201: [86, 88, 89, 265, 268, 406],\n",
       " 203: [415],\n",
       " 208: [96, 449],\n",
       " 209: [95, 280, 363],\n",
       " 210: [380],\n",
       " 211: [381],\n",
       " 212: [342],\n",
       " 214: [246],\n",
       " 215: [119],\n",
       " 216: [352],\n",
       " 218: [290],\n",
       " 219: [7],\n",
       " 221: [241],\n",
       " 231: [142],\n",
       " 237: [68, 318, 489],\n",
       " 238: [72, 143],\n",
       " 241: [221],\n",
       " 242: [251],\n",
       " 243: [252],\n",
       " 244: [116, 347],\n",
       " 246: [214],\n",
       " 251: [242],\n",
       " 252: [243],\n",
       " 254: [261],\n",
       " 259: [86, 87, 199, 200, 264, 265, 405],\n",
       " 261: [254],\n",
       " 262: [377],\n",
       " 263: [105],\n",
       " 264: [86, 87, 199, 200, 259, 265, 405],\n",
       " 265: [86, 87, 88, 89, 199, 200, 201, 259, 264, 268, 405, 406],\n",
       " 266: [385],\n",
       " 267: [386],\n",
       " 268: [86, 87, 88, 89, 201, 265, 405, 406],\n",
       " 273: [326],\n",
       " 274: [140],\n",
       " 276: [445],\n",
       " 279: [457],\n",
       " 280: [95, 209],\n",
       " 281: [34],\n",
       " 285: [491],\n",
       " 288: [314],\n",
       " 290: [218],\n",
       " 292: [404],\n",
       " 304: [187],\n",
       " 307: [4],\n",
       " 313: [193],\n",
       " 314: [184, 288],\n",
       " 318: [68, 237],\n",
       " 326: [273],\n",
       " 327: [167, 329],\n",
       " 329: [167, 327],\n",
       " 333: [71],\n",
       " 334: [72],\n",
       " 339: [19, 171],\n",
       " 340: [171],\n",
       " 341: [52],\n",
       " 342: [212],\n",
       " 347: [244],\n",
       " 349: [117, 118],\n",
       " 350: [106],\n",
       " 352: [216],\n",
       " 353: [463],\n",
       " 354: [152, 153, 366, 454, 467],\n",
       " 358: [21, 22, 173, 174, 359, 496],\n",
       " 359: [21, 22, 173, 174, 358, 496],\n",
       " 360: [74, 76],\n",
       " 363: [209],\n",
       " 366: [152, 153, 354, 454, 467],\n",
       " 368: [369],\n",
       " 369: [368],\n",
       " 377: [262],\n",
       " 378: [383],\n",
       " 379: [81],\n",
       " 380: [210],\n",
       " 381: [211],\n",
       " 383: [378],\n",
       " 385: [266],\n",
       " 386: [267],\n",
       " 389: [107, 108],\n",
       " 390: [109, 391],\n",
       " 391: [109, 390],\n",
       " 393: [83],\n",
       " 397: [112, 113, 419],\n",
       " 404: [292],\n",
       " 405: [87, 88, 89, 199, 259, 264, 265, 268, 406],\n",
       " 406: [86, 87, 88, 89, 201, 265, 268, 405],\n",
       " 408: [45],\n",
       " 415: [203],\n",
       " 419: [112, 113, 397],\n",
       " 420: [41],\n",
       " 431: [57, 62, 63, 64, 432],\n",
       " 432: [57, 62, 63, 64, 431],\n",
       " 437: [183],\n",
       " 438: [49],\n",
       " 439: [440, 441, 442],\n",
       " 440: [23, 439, 442],\n",
       " 441: [439],\n",
       " 442: [23, 439, 440],\n",
       " 443: [51],\n",
       " 445: [276],\n",
       " 449: [208],\n",
       " 451: [26, 27],\n",
       " 453: [28],\n",
       " 454: [152, 153, 354, 366, 467],\n",
       " 455: [485],\n",
       " 457: [279],\n",
       " 461: [31, 462],\n",
       " 462: [31, 461],\n",
       " 463: [353],\n",
       " 467: [152, 153, 354, 366, 454],\n",
       " 469: [470],\n",
       " 470: [469],\n",
       " 472: [178],\n",
       " 476: [116],\n",
       " 479: [14, 483, 484],\n",
       " 480: [36, 481],\n",
       " 481: [36, 480],\n",
       " 483: [14, 479],\n",
       " 484: [479],\n",
       " 485: [455],\n",
       " 487: [19],\n",
       " 489: [237],\n",
       " 491: [285],\n",
       " 493: [18],\n",
       " 495: [172],\n",
       " 496: [21, 173, 174, 358, 359]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Индексы товаров с похожими описаниями, для описаний, векторизированных с помощью Word2Vec\n",
    "result_dict_w2v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
